## 先验概率、后验概率
先验分布与后验分布的区分点在于是否引入或者使用了新的信息(某个事实)，即使用了新信息的为后验概率，没有使用新信息的为先验概率

## 熵
$$H(X)=-\sum_{i=1}^{n}p_i*log(p_i)$$ (1)
其中，对数以2或e为底，单位分别为比特、纳特。
## 信息增益
特征A对训练数据集D的信息增益：
$$g(D,A)=H(D)-H(D|A)$$ (2)
其中，$H(D)$，$H(D|A)$中的概率由数据估计(极大似然估计)得到，分别称为经验熵，经验条件熵。(依据提供的条件，数据的混乱程度减小，熵减小)  
当$H(D)$，$H(D|A)$为熵，条件熵时(2)式的值称为互信息(mutual information)。
## 信息增益比
使用信息增益作为划分训练数据集的特征时，会趋向于选择特征数较多的特征，信息增益比可以解决这个问题。  
特征A对训练数据集D的信息增益比：
$$g_{_R}(D,A)=\frac{g(D,A)}{H_{_A}(D)}$$
$$H_{_A}(D)=$$
## 基尼指数
$$Gini(p)=\sum_{k=1}^{K}p_k*(1-p_k)$$